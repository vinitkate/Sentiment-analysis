{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e91497ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\VinitKate\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\VinitKate\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package cmudict to\n",
      "[nltk_data]     C:\\Users\\VinitKate\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package cmudict is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('cmudict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "32db0db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_urls = pd.read_csv('input.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1a662781",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getText(text, req=['h1', 'p']):\n",
    "    useful = ''\n",
    "    for t in text:\n",
    "        if t.parent.name in req:\n",
    "            useful += '{} '.format(t)\n",
    "    return useful\n",
    "\n",
    "ROOT_DIR = os.curdir\n",
    "\n",
    "def saveFile(name, content):\n",
    "    if not os.path.isdir(os.path.join(ROOT_DIR, 'textFiles')):\n",
    "        os.mkdir(os.path.join(ROOT_DIR, 'textFiles'))\n",
    "    targetPath = os.path.join(ROOT_DIR, 'textFiles', name+'.txt')\n",
    "    with open(targetPath, 'w', encoding='utf-8') as file:\n",
    "        file.write(content)\n",
    "\n",
    "# --------- FOR IMPORTING DATA ============ uncomment the following if want to download data may take time\n",
    "# for i in range(len(data_urls['URL'])):\n",
    "#     url = data_urls['URL'][i]\n",
    "#     urlID = data_urls['URL_ID'][i]\n",
    "#     res = requests.get(url)\n",
    "#     html_pg = res.content\n",
    "#     soup = BeautifulSoup(html_pg, 'html.parser')\n",
    "#     text = soup.find_all(text=True)\n",
    "#     text = getText(text)\n",
    "#     text = text[:text.rindex('Contact us')]\n",
    "#     fileName = urlID\n",
    "#     saveFile(str(urlID), text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "05ea750d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWordFileDest = os.path.join(os.curdir, 'StopWords')\n",
    "fileNames = os.listdir(stopWordFileDest)\n",
    "stop_words = []\n",
    "for fileName in fileNames:\n",
    "    with open(os.path.join(stopWordFileDest, fileName), 'r') as file:\n",
    "        for line in file:\n",
    "            st = line.rstrip()\n",
    "            f = st.split(\" | \")\n",
    "            for w in f:\n",
    "                stop_words.append(w.strip())\n",
    "        \n",
    "# stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "40f687b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "positiveDict = []\n",
    "with open('positive-words.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        positiveDict.append(line.rstrip())\n",
    "\n",
    "negativeDict = []\n",
    "with open('negative-words.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        negativeDict.append(line.rstrip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d66e1bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_complex(word):\n",
    "    syllables = 0\n",
    "    vowels = ['a', 'e', 'i', 'o', 'u']\n",
    "    for w in word:\n",
    "        if w in vowels:\n",
    "            syllables += 1    \n",
    "    return syllables >= 2\n",
    "\n",
    "def numberOfComplexWords(data, words):\n",
    "    complex_word_count = 0\n",
    "    for word in words:\n",
    "        if is_complex(word):\n",
    "            complex_word_count += 1\n",
    "    return complex_word_count\n",
    "\n",
    "def numberOfPersonalPronouns(data, words, pronouns=['i', 'me', 'my', 'mine', 'we', 'us', 'our', 'ours']):\n",
    "#     words = word_tokenize(data)\n",
    "    personalPronouns = 0\n",
    "    for word in words:\n",
    "        if word.lower() in pronouns:\n",
    "            personalPronouns += 1\n",
    "    return personalPronouns\n",
    "\n",
    "def syllablePerWord(data, words):\n",
    "    syllables = 0\n",
    "    vowels = ['a', 'e', 'i', 'o', 'u']\n",
    "    for word in words:\n",
    "        if word.endswith('ed') or word.endswith('es'):\n",
    "            continue\n",
    "        temp = 0\n",
    "        for w in word.lower():\n",
    "            if w in vowels:\n",
    "                temp += 1\n",
    "        \n",
    "        syllables += temp\n",
    "            \n",
    "    if len(words) > 0:\n",
    "        return syllables / len(words)\n",
    "    return 0\n",
    "\n",
    "def totalWords(data, words):\n",
    "    return len(words)\n",
    "\n",
    "def averageWordLength(data, words):\n",
    "    charCount = sum(len(word) for word in words)\n",
    "    if len(words) > 0:\n",
    "        return charCount / len(words)\n",
    "    return 0\n",
    "\n",
    "def averageWordsPerSentense(data, sentenses):\n",
    "    words = 0\n",
    "    for sentense in sentenses:\n",
    "        wds = word_tokenize(sentense)\n",
    "        words += len(wds)\n",
    "        \n",
    "    if len(sentenses) > 0:\n",
    "        return words / len(sentenses)\n",
    "    return 0\n",
    "\n",
    "def fogIndex(data, sentenses, words):\n",
    "    complex_words = numberOfComplexWords(data, words)\n",
    "    total_words = totalWords(data, words)\n",
    "    total_sentenses = len(sentenses)\n",
    "    return 0.4*((total_words/total_sentenses) \n",
    "                + 100*(complex_words/total_words))\n",
    "\n",
    "def percentComplexWords(data, words):\n",
    "    complex_words = numberOfComplexWords(data, words)\n",
    "    total_words = totalWords(data, words)\n",
    "    return (complex_words/total_words)*100\n",
    "\n",
    "def averageSentenseLength(data, sentenses):\n",
    "    sentensesLength = sum(len(sentense) for sentense in sentenses)\n",
    "    if len(sentenses) > 0:\n",
    "        return sentensesLength / len(sentenses)\n",
    "    return 0\n",
    "\n",
    "def polarity(positive, negative):\n",
    "    return (positive - negative)/(positive + negative) + 10**(-6)\n",
    "    \n",
    "\n",
    "def subjectivity(data, words):\n",
    "    tws = totalWords(data, words)\n",
    "    pos, neg = positiveNegativeScore(data, words)\n",
    "    return (pos + neg) / tws + 10**(-6)\n",
    "    \n",
    "def positiveNegativeScore(data, words):\n",
    "    positive, negative = 0, 0\n",
    "    for word in words:\n",
    "        if word in positiveDict:\n",
    "            positive += 1\n",
    "        elif word in negativeDict:\n",
    "            negative += 1\n",
    "    \n",
    "    return (positive, negative)\n",
    "\n",
    "def clean(data):\n",
    "    \n",
    "    #Removing URLs with a regular expression\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    data = url_pattern.sub(r'', data)\n",
    "\n",
    "    # Remove Emails\n",
    "    data = re.sub('\\S*@\\S*\\s?', '', data)\n",
    "\n",
    "#     Remove new line characters\n",
    "    data = re.sub('\\s+', ' ', data)\n",
    "\n",
    "    # Remove single quotes\n",
    "    data = re.sub(\"\\'\", \"\", data)\n",
    "    \n",
    "    #Remove comma, fullstop\n",
    "    data = re.sub(r'[^\\w\\s]', '', data)\n",
    "        \n",
    "    return data\n",
    "\n",
    "def removeStopWords(data):\n",
    "    words = data.split(\" \")\n",
    "    for i in range(len(words)):\n",
    "        if words[i] in stop_words:\n",
    "            words[i] = \"\"\n",
    "            \n",
    "    return \" \".join(map(str, words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1e03cf3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>SYLLABLE PER WORD</th>\n",
       "      <th>PERSONAL PRONOUNS</th>\n",
       "      <th>AVG WORD LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>146</td>\n",
       "      <td>https://insights.blackcoffer.com/blockchain-fo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>147</td>\n",
       "      <td>https://insights.blackcoffer.com/the-future-of...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>148</td>\n",
       "      <td>https://insights.blackcoffer.com/big-data-anal...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>149</td>\n",
       "      <td>https://insights.blackcoffer.com/business-anal...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>150</td>\n",
       "      <td>https://insights.blackcoffer.com/challenges-an...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     URL_ID                                                URL  \\\n",
       "0        37  https://insights.blackcoffer.com/ai-in-healthc...   \n",
       "1        38  https://insights.blackcoffer.com/what-if-the-c...   \n",
       "2        39  https://insights.blackcoffer.com/what-jobs-wil...   \n",
       "3        40  https://insights.blackcoffer.com/will-machine-...   \n",
       "4        41  https://insights.blackcoffer.com/will-ai-repla...   \n",
       "..      ...                                                ...   \n",
       "109     146  https://insights.blackcoffer.com/blockchain-fo...   \n",
       "110     147  https://insights.blackcoffer.com/the-future-of...   \n",
       "111     148  https://insights.blackcoffer.com/big-data-anal...   \n",
       "112     149  https://insights.blackcoffer.com/business-anal...   \n",
       "113     150  https://insights.blackcoffer.com/challenges-an...   \n",
       "\n",
       "     POSITIVE SCORE  NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  \\\n",
       "0               NaN             NaN             NaN                 NaN   \n",
       "1               NaN             NaN             NaN                 NaN   \n",
       "2               NaN             NaN             NaN                 NaN   \n",
       "3               NaN             NaN             NaN                 NaN   \n",
       "4               NaN             NaN             NaN                 NaN   \n",
       "..              ...             ...             ...                 ...   \n",
       "109             NaN             NaN             NaN                 NaN   \n",
       "110             NaN             NaN             NaN                 NaN   \n",
       "111             NaN             NaN             NaN                 NaN   \n",
       "112             NaN             NaN             NaN                 NaN   \n",
       "113             NaN             NaN             NaN                 NaN   \n",
       "\n",
       "     AVG SENTENCE LENGTH  PERCENTAGE OF COMPLEX WORDS  FOG INDEX  \\\n",
       "0                    NaN                          NaN        NaN   \n",
       "1                    NaN                          NaN        NaN   \n",
       "2                    NaN                          NaN        NaN   \n",
       "3                    NaN                          NaN        NaN   \n",
       "4                    NaN                          NaN        NaN   \n",
       "..                   ...                          ...        ...   \n",
       "109                  NaN                          NaN        NaN   \n",
       "110                  NaN                          NaN        NaN   \n",
       "111                  NaN                          NaN        NaN   \n",
       "112                  NaN                          NaN        NaN   \n",
       "113                  NaN                          NaN        NaN   \n",
       "\n",
       "     AVG NUMBER OF WORDS PER SENTENCE  COMPLEX WORD COUNT  WORD COUNT  \\\n",
       "0                                 NaN                 NaN         NaN   \n",
       "1                                 NaN                 NaN         NaN   \n",
       "2                                 NaN                 NaN         NaN   \n",
       "3                                 NaN                 NaN         NaN   \n",
       "4                                 NaN                 NaN         NaN   \n",
       "..                                ...                 ...         ...   \n",
       "109                               NaN                 NaN         NaN   \n",
       "110                               NaN                 NaN         NaN   \n",
       "111                               NaN                 NaN         NaN   \n",
       "112                               NaN                 NaN         NaN   \n",
       "113                               NaN                 NaN         NaN   \n",
       "\n",
       "     SYLLABLE PER WORD  PERSONAL PRONOUNS  AVG WORD LENGTH  \n",
       "0                  NaN                NaN              NaN  \n",
       "1                  NaN                NaN              NaN  \n",
       "2                  NaN                NaN              NaN  \n",
       "3                  NaN                NaN              NaN  \n",
       "4                  NaN                NaN              NaN  \n",
       "..                 ...                ...              ...  \n",
       "109                NaN                NaN              NaN  \n",
       "110                NaN                NaN              NaN  \n",
       "111                NaN                NaN              NaN  \n",
       "112                NaN                NaN              NaN  \n",
       "113                NaN                NaN              NaN  \n",
       "\n",
       "[114 rows x 15 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textFileDest = os.path.join(os.path.curdir, 'textFiles')\n",
    "\n",
    "out_df = pd.read_csv('outputData.csv')\n",
    "\n",
    "# files = os.listdir(textFileDest)\n",
    "out_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "78449e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(textFileDest):\n",
    "#     print(file)\n",
    "    fileDest = os.path.join(textFileDest, file)\n",
    "    with open(fileDest, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "        dataWithoutStop = removeStopWords(text)\n",
    "        data = clean(dataWithoutStop)\n",
    "        row = out_df[out_df['URL_ID'] == int(file[:file.find('.txt')])].index\n",
    "        words = word_tokenize(data)\n",
    "        sentenses = sent_tokenize(dataWithoutStop)\n",
    "        pos, neg = positiveNegativeScore(data, words)\n",
    "        out_df.loc[row, 'POSITIVE SCORE'], out_df.loc[row, 'NEGATIVE SCORE'] = pos, neg\n",
    "        out_df.loc[row, 'POLARITY SCORE'] = polarity(pos, neg)\n",
    "        out_df.loc[row, 'SUBJECTIVITY SCORE'] = subjectivity(data, words)\n",
    "        out_df.loc[row, 'AVG SENTENCE LENGTH'] = averageSentenseLength(dataWithoutStop, sentenses)\n",
    "        out_df.loc[row, 'PERCENTAGE OF COMPLEX WORDS'] = percentComplexWords(data, words)\n",
    "        out_df.loc[row, 'FOG INDEX'] = fogIndex(data, sentenses, words)\n",
    "        out_df.loc[row, 'AVG NUMBER OF WORDS PER SENTENCE'] = averageWordsPerSentense(dataWithoutStop, sentenses)\n",
    "        out_df.loc[row, 'COMPLEX WORD COUNT'] = numberOfComplexWords(data, words)\n",
    "        out_df.loc[row, 'WORD COUNT'] = totalWords(data, words)\n",
    "        out_df.loc[row, 'SYLLABLE PER WORD'] = syllablePerWord(data, words)\n",
    "        out_df.loc[row, 'PERSONAL PRONOUNS'] = numberOfPersonalPronouns(data, words)\n",
    "        out_df.loc[row, 'AVG WORD LENGTH'] = averageWordLength(data, words)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8933a420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>SYLLABLE PER WORD</th>\n",
       "      <th>PERSONAL PRONOUNS</th>\n",
       "      <th>AVG WORD LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "      <td>64.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.319589</td>\n",
       "      <td>0.090995</td>\n",
       "      <td>133.486486</td>\n",
       "      <td>85.928705</td>\n",
       "      <td>40.133644</td>\n",
       "      <td>17.405405</td>\n",
       "      <td>916.0</td>\n",
       "      <td>1066.0</td>\n",
       "      <td>2.420263</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.429644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "      <td>59.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.229168</td>\n",
       "      <td>0.134267</td>\n",
       "      <td>78.333333</td>\n",
       "      <td>72.167832</td>\n",
       "      <td>32.397997</td>\n",
       "      <td>11.765432</td>\n",
       "      <td>516.0</td>\n",
       "      <td>715.0</td>\n",
       "      <td>2.055944</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.639161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "      <td>67.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.340001</td>\n",
       "      <td>0.105043</td>\n",
       "      <td>102.290698</td>\n",
       "      <td>85.189076</td>\n",
       "      <td>38.503537</td>\n",
       "      <td>13.662791</td>\n",
       "      <td>811.0</td>\n",
       "      <td>952.0</td>\n",
       "      <td>2.341387</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.301471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "      <td>59.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.439025</td>\n",
       "      <td>0.110364</td>\n",
       "      <td>73.222222</td>\n",
       "      <td>76.446837</td>\n",
       "      <td>33.880957</td>\n",
       "      <td>10.233333</td>\n",
       "      <td>568.0</td>\n",
       "      <td>743.0</td>\n",
       "      <td>2.259758</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.648721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.378379</td>\n",
       "      <td>0.080875</td>\n",
       "      <td>104.384615</td>\n",
       "      <td>77.704918</td>\n",
       "      <td>35.774275</td>\n",
       "      <td>14.769231</td>\n",
       "      <td>711.0</td>\n",
       "      <td>915.0</td>\n",
       "      <td>2.209836</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.821858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>146</td>\n",
       "      <td>https://insights.blackcoffer.com/blockchain-fo...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.100001</td>\n",
       "      <td>97.854167</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>36.333333</td>\n",
       "      <td>12.812500</td>\n",
       "      <td>416.0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>2.205769</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.157692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>147</td>\n",
       "      <td>https://insights.blackcoffer.com/the-future-of...</td>\n",
       "      <td>39.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.560001</td>\n",
       "      <td>0.078617</td>\n",
       "      <td>112.480000</td>\n",
       "      <td>77.987421</td>\n",
       "      <td>36.282969</td>\n",
       "      <td>15.560000</td>\n",
       "      <td>496.0</td>\n",
       "      <td>636.0</td>\n",
       "      <td>2.226415</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.904088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>148</td>\n",
       "      <td>https://insights.blackcoffer.com/big-data-anal...</td>\n",
       "      <td>29.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>-0.147058</td>\n",
       "      <td>0.104136</td>\n",
       "      <td>86.969231</td>\n",
       "      <td>79.938744</td>\n",
       "      <td>35.993959</td>\n",
       "      <td>12.138462</td>\n",
       "      <td>522.0</td>\n",
       "      <td>653.0</td>\n",
       "      <td>2.361409</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.803982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>149</td>\n",
       "      <td>https://insights.blackcoffer.com/business-anal...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.823530</td>\n",
       "      <td>0.096318</td>\n",
       "      <td>125.884615</td>\n",
       "      <td>84.135977</td>\n",
       "      <td>39.085160</td>\n",
       "      <td>16.076923</td>\n",
       "      <td>297.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>2.439093</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.453258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>150</td>\n",
       "      <td>https://insights.blackcoffer.com/challenges-an...</td>\n",
       "      <td>39.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.026317</td>\n",
       "      <td>0.132175</td>\n",
       "      <td>76.815385</td>\n",
       "      <td>78.956522</td>\n",
       "      <td>35.121070</td>\n",
       "      <td>10.476923</td>\n",
       "      <td>454.0</td>\n",
       "      <td>575.0</td>\n",
       "      <td>2.220870</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.801739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     URL_ID                                                URL  \\\n",
       "0        37  https://insights.blackcoffer.com/ai-in-healthc...   \n",
       "1        38  https://insights.blackcoffer.com/what-if-the-c...   \n",
       "2        39  https://insights.blackcoffer.com/what-jobs-wil...   \n",
       "3        40  https://insights.blackcoffer.com/will-machine-...   \n",
       "4        41  https://insights.blackcoffer.com/will-ai-repla...   \n",
       "..      ...                                                ...   \n",
       "109     146  https://insights.blackcoffer.com/blockchain-fo...   \n",
       "110     147  https://insights.blackcoffer.com/the-future-of...   \n",
       "111     148  https://insights.blackcoffer.com/big-data-anal...   \n",
       "112     149  https://insights.blackcoffer.com/business-anal...   \n",
       "113     150  https://insights.blackcoffer.com/challenges-an...   \n",
       "\n",
       "     POSITIVE SCORE  NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  \\\n",
       "0              64.0            33.0        0.319589            0.090995   \n",
       "1              59.0            37.0        0.229168            0.134267   \n",
       "2              67.0            33.0        0.340001            0.105043   \n",
       "3              59.0            23.0        0.439025            0.110364   \n",
       "4              51.0            23.0        0.378379            0.080875   \n",
       "..              ...             ...             ...                 ...   \n",
       "109            26.0            26.0        0.000001            0.100001   \n",
       "110            39.0            11.0        0.560001            0.078617   \n",
       "111            29.0            39.0       -0.147058            0.104136   \n",
       "112            31.0             3.0        0.823530            0.096318   \n",
       "113            39.0            37.0        0.026317            0.132175   \n",
       "\n",
       "     AVG SENTENCE LENGTH  PERCENTAGE OF COMPLEX WORDS  FOG INDEX  \\\n",
       "0             133.486486                    85.928705  40.133644   \n",
       "1              78.333333                    72.167832  32.397997   \n",
       "2             102.290698                    85.189076  38.503537   \n",
       "3              73.222222                    76.446837  33.880957   \n",
       "4             104.384615                    77.704918  35.774275   \n",
       "..                   ...                          ...        ...   \n",
       "109            97.854167                    80.000000  36.333333   \n",
       "110           112.480000                    77.987421  36.282969   \n",
       "111            86.969231                    79.938744  35.993959   \n",
       "112           125.884615                    84.135977  39.085160   \n",
       "113            76.815385                    78.956522  35.121070   \n",
       "\n",
       "     AVG NUMBER OF WORDS PER SENTENCE  COMPLEX WORD COUNT  WORD COUNT  \\\n",
       "0                           17.405405               916.0      1066.0   \n",
       "1                           11.765432               516.0       715.0   \n",
       "2                           13.662791               811.0       952.0   \n",
       "3                           10.233333               568.0       743.0   \n",
       "4                           14.769231               711.0       915.0   \n",
       "..                                ...                 ...         ...   \n",
       "109                         12.812500               416.0       520.0   \n",
       "110                         15.560000               496.0       636.0   \n",
       "111                         12.138462               522.0       653.0   \n",
       "112                         16.076923               297.0       353.0   \n",
       "113                         10.476923               454.0       575.0   \n",
       "\n",
       "     SYLLABLE PER WORD  PERSONAL PRONOUNS  AVG WORD LENGTH  \n",
       "0             2.420263                2.0         7.429644  \n",
       "1             2.055944                1.0         6.639161  \n",
       "2             2.341387                1.0         7.301471  \n",
       "3             2.259758                2.0         6.648721  \n",
       "4             2.209836                6.0         6.821858  \n",
       "..                 ...                ...              ...  \n",
       "109           2.205769                5.0         7.157692  \n",
       "110           2.226415                2.0         6.904088  \n",
       "111           2.361409                2.0         6.803982  \n",
       "112           2.439093                1.0         7.453258  \n",
       "113           2.220870                1.0         6.801739  \n",
       "\n",
       "[114 rows x 15 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0a9c064b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['URL_ID', 'URL', 'POSITIVE SCORE', 'NEGATIVE SCORE', 'POLARITY SCORE',\n",
       "       'SUBJECTIVITY SCORE', 'AVG SENTENCE LENGTH',\n",
       "       'PERCENTAGE OF COMPLEX WORDS', 'FOG INDEX',\n",
       "       'AVG NUMBER OF WORDS PER SENTENCE', 'COMPLEX WORD COUNT', 'WORD COUNT',\n",
       "       'SYLLABLE PER WORD', 'PERSONAL PRONOUNS', 'AVG WORD LENGTH'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "598da2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df.to_csv('Answers.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5f64fbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "for file in os.listdir(textFileDest):\n",
    "#     print(file)\n",
    "    fileDest = os.path.join(textFileDest, file)\n",
    "    with open(fileDest, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "        dataWithoutStop = removeStopWords(text)\n",
    "        data = clean(dataWithoutStop)\n",
    "        row = out_df[out_df['URL_ID'] == int(file[:file.find('.txt')])].index\n",
    "        words = word_tokenize(data)\n",
    "        sentenses = sent_tokenize(dataWithoutStop)\n",
    "        pos, neg = positiveNegativeScore(data, words)\n",
    "        out_df.loc[row, 'POSITIVE SCORE'], out_df.loc[row, 'NEGATIVE SCORE'] = pos, neg\n",
    "        out_df.loc[row, 'POLARITY SCORE'] = polarity(pos, neg)\n",
    "        out_df.loc[row, 'SUBJECTIVITY SCORE'] = subjectivity(data, words)\n",
    "        out_df.loc[row, 'AVG SENTENCE LENGTH'] = math.floor(averageSentenseLength(dataWithoutStop, sentenses))\n",
    "        out_df.loc[row, 'PERCENTAGE OF COMPLEX WORDS'] = percentComplexWords(data, words)\n",
    "        out_df.loc[row, 'FOG INDEX'] = fogIndex(data, sentenses, words)\n",
    "        out_df.loc[row, 'AVG NUMBER OF WORDS PER SENTENCE'] = math.floor(averageWordsPerSentense(dataWithoutStop, sentenses))\n",
    "        out_df.loc[row, 'COMPLEX WORD COUNT'] = numberOfComplexWords(data, words)\n",
    "        out_df.loc[row, 'WORD COUNT'] = totalWords(data, words)\n",
    "        out_df.loc[row, 'SYLLABLE PER WORD'] = syllablePerWord(data, words)\n",
    "        out_df.loc[row, 'PERSONAL PRONOUNS'] = numberOfPersonalPronouns(data, words)\n",
    "        out_df.loc[row, 'AVG WORD LENGTH'] = math.floor(averageWordLength(data, words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e6f2ddb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df.to_csv('Answers.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec79b5af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
